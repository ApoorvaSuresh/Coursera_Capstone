{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Car Accident Severity Prediction for Driver Warning and Assistance Systems"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Applied Data Science Capstone, IBM Data Science Professional Certificate"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Table of Contents"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "1. Introduction\n2. Data\n3. Methodology\n4. Results and Evaluation\n5. Discussion\n6. Conclusion"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Introduction and Business Understanding"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Background:\nCar accidents could occur due to several factors. Some of the most important ones are road conditions, weather and visibility conditions. These conditions also influence the severity of the accidents. In this study, we try to predict the severity of car accidents through reliable and robust machine learning models. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Business Problem:\nThere could be several factors that influence the occurrence and severity of car accidents. This study aims to investigate three main factors: Weather, Road conditions and Visibility conditions on the severity of accidents. A robust algorithm must be developed to predict the severity of accidents, so that the drivers could be warned about it. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Interest:\nThe Seattle transportation department would be very interested in predicting the severity of accidents and so, make the target audience for this case study. Since the study deals with predicting the severity of car accidents, the results would be particularly helpful for them to plan and improve the road conditions in the city and placement of street lights. They would also be curious to know the influence of other factors like weather and visibility conditions on the occurrence of accidents and the level of severity. The results of this study could also be useful to the drivers to show them the consequences of driving under these conditions. Another interesting application of this study is to assist the Active safety or Driver Assistance Systems of cars about the current driving conditions, in order to enhance the development and performance of such systems. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Data"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Data loading und understanding"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n"
                }
            ],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SEVERITYCODE</th>\n      <th>X</th>\n      <th>Y</th>\n      <th>OBJECTID</th>\n      <th>INCKEY</th>\n      <th>COLDETKEY</th>\n      <th>REPORTNO</th>\n      <th>STATUS</th>\n      <th>ADDRTYPE</th>\n      <th>INTKEY</th>\n      <th>...</th>\n      <th>ROADCOND</th>\n      <th>LIGHTCOND</th>\n      <th>PEDROWNOTGRNT</th>\n      <th>SDOTCOLNUM</th>\n      <th>SPEEDING</th>\n      <th>ST_COLCODE</th>\n      <th>ST_COLDESC</th>\n      <th>SEGLANEKEY</th>\n      <th>CROSSWALKKEY</th>\n      <th>HITPARKEDCAR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>-122.323148</td>\n      <td>47.703140</td>\n      <td>1</td>\n      <td>1307</td>\n      <td>1307</td>\n      <td>3502005</td>\n      <td>Matched</td>\n      <td>Intersection</td>\n      <td>37475.0</td>\n      <td>...</td>\n      <td>Wet</td>\n      <td>Daylight</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10</td>\n      <td>Entering at angle</td>\n      <td>0</td>\n      <td>0</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>-122.347294</td>\n      <td>47.647172</td>\n      <td>2</td>\n      <td>52200</td>\n      <td>52200</td>\n      <td>2607959</td>\n      <td>Matched</td>\n      <td>Block</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>Wet</td>\n      <td>Dark - Street Lights On</td>\n      <td>NaN</td>\n      <td>6354039.0</td>\n      <td>NaN</td>\n      <td>11</td>\n      <td>From same direction - both going straight - bo...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>-122.334540</td>\n      <td>47.607871</td>\n      <td>3</td>\n      <td>26700</td>\n      <td>26700</td>\n      <td>1482393</td>\n      <td>Matched</td>\n      <td>Block</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>Dry</td>\n      <td>Daylight</td>\n      <td>NaN</td>\n      <td>4323031.0</td>\n      <td>NaN</td>\n      <td>32</td>\n      <td>One parked--one moving</td>\n      <td>0</td>\n      <td>0</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>-122.334803</td>\n      <td>47.604803</td>\n      <td>4</td>\n      <td>1144</td>\n      <td>1144</td>\n      <td>3503937</td>\n      <td>Matched</td>\n      <td>Block</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>Dry</td>\n      <td>Daylight</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>23</td>\n      <td>From same direction - all others</td>\n      <td>0</td>\n      <td>0</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>-122.306426</td>\n      <td>47.545739</td>\n      <td>5</td>\n      <td>17700</td>\n      <td>17700</td>\n      <td>1807429</td>\n      <td>Matched</td>\n      <td>Intersection</td>\n      <td>34387.0</td>\n      <td>...</td>\n      <td>Wet</td>\n      <td>Daylight</td>\n      <td>NaN</td>\n      <td>4028032.0</td>\n      <td>NaN</td>\n      <td>10</td>\n      <td>Entering at angle</td>\n      <td>0</td>\n      <td>0</td>\n      <td>N</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 38 columns</p>\n</div>",
                        "text/plain": "   SEVERITYCODE           X          Y  OBJECTID  INCKEY  COLDETKEY REPORTNO  \\\n0             2 -122.323148  47.703140         1    1307       1307  3502005   \n1             1 -122.347294  47.647172         2   52200      52200  2607959   \n2             1 -122.334540  47.607871         3   26700      26700  1482393   \n3             1 -122.334803  47.604803         4    1144       1144  3503937   \n4             2 -122.306426  47.545739         5   17700      17700  1807429   \n\n    STATUS      ADDRTYPE   INTKEY  ... ROADCOND                LIGHTCOND  \\\n0  Matched  Intersection  37475.0  ...      Wet                 Daylight   \n1  Matched         Block      NaN  ...      Wet  Dark - Street Lights On   \n2  Matched         Block      NaN  ...      Dry                 Daylight   \n3  Matched         Block      NaN  ...      Dry                 Daylight   \n4  Matched  Intersection  34387.0  ...      Wet                 Daylight   \n\n  PEDROWNOTGRNT  SDOTCOLNUM SPEEDING ST_COLCODE  \\\n0           NaN         NaN      NaN         10   \n1           NaN   6354039.0      NaN         11   \n2           NaN   4323031.0      NaN         32   \n3           NaN         NaN      NaN         23   \n4           NaN   4028032.0      NaN         10   \n\n                                          ST_COLDESC  SEGLANEKEY  \\\n0                                  Entering at angle           0   \n1  From same direction - both going straight - bo...           0   \n2                             One parked--one moving           0   \n3                   From same direction - all others           0   \n4                                  Entering at angle           0   \n\n   CROSSWALKKEY  HITPARKEDCAR  \n0             0             N  \n1             0             N  \n2             0             N  \n3             0             N  \n4             0             N  \n\n[5 rows x 38 columns]"
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The data being used in this study is the collision reports from Seattle, collected over several years (2004-present) by the Seattle Police Department and Traffic Records department. The data has 37 independent variables and 194,673 records. There are several attributes in this data, but the ones that are of interest in this study are: \u201cWEATHER\u201d, \u201cROADCOND\u201d and \u201cLIGHTCOND\u201d. Different conditions of weather, road and light conditions are mentioned in the data. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The target variable is \u201cSEVERITYCODE\u201d. It is made up of numbers, which correspond to different levels of severity:\n* 0 No/negligible probability: no/negligible chance \n* 1 Very low probability: Chance of car damage\n* 2 Low probability: Chance of injury and/or car damage\n* 3 Mild probability: Chance of serious injury and car damage\n* 4 High probability: Fatal and car damage"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Data Pre-processing"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Most columns are of type \u2018object\u2019 and even if there are numbers, they might correspond to different categories. Some columns and rows have null values, which will be dealt with during this phase. We must use label encoding on these columns to convert the features to numbers. But first, we should drop the columns which are not required for this study."
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SEVERITYCODE</th>\n      <th>WEATHER</th>\n      <th>ROADCOND</th>\n      <th>LIGHTCOND</th>\n      <th>WEATHER_CAT</th>\n      <th>ROADCOND_CAT</th>\n      <th>LIGHTCOND_CAT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>Overcast</td>\n      <td>Wet</td>\n      <td>Daylight</td>\n      <td>4</td>\n      <td>8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Raining</td>\n      <td>Wet</td>\n      <td>Dark - Street Lights On</td>\n      <td>6</td>\n      <td>8</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Overcast</td>\n      <td>Dry</td>\n      <td>Daylight</td>\n      <td>4</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Clear</td>\n      <td>Dry</td>\n      <td>Daylight</td>\n      <td>1</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>Raining</td>\n      <td>Wet</td>\n      <td>Daylight</td>\n      <td>6</td>\n      <td>8</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   SEVERITYCODE   WEATHER ROADCOND                LIGHTCOND  WEATHER_CAT  \\\n0             2  Overcast      Wet                 Daylight            4   \n1             1   Raining      Wet  Dark - Street Lights On            6   \n2             1  Overcast      Dry                 Daylight            4   \n3             1     Clear      Dry                 Daylight            1   \n4             2   Raining      Wet                 Daylight            6   \n\n   ROADCOND_CAT  LIGHTCOND_CAT  \n0             8              5  \n1             8              2  \n2             0              5  \n3             0              5  \n4             8              5  "
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# Drop all columns with no predictive value for the context of this project\npro_data = df.drop(columns = ['OBJECTID', 'SEVERITYCODE.1', 'REPORTNO', 'INCKEY', 'COLDETKEY', \n              'X', 'Y', 'STATUS','ADDRTYPE',\n              'INTKEY', 'LOCATION', 'EXCEPTRSNCODE',\n              'EXCEPTRSNDESC', 'SEVERITYDESC', 'INCDATE',\n              'INCDTTM', 'JUNCTIONTYPE', 'SDOT_COLCODE',\n              'SDOT_COLDESC', 'PEDROWNOTGRNT', 'SDOTCOLNUM',\n              'ST_COLCODE', 'ST_COLDESC', 'SEGLANEKEY',\n              'CROSSWALKKEY', 'HITPARKEDCAR', 'PEDCOUNT', 'PEDCYLCOUNT',\n              'PERSONCOUNT', 'VEHCOUNT', 'COLLISIONTYPE',\n              'SPEEDING', 'UNDERINFL', 'INATTENTIONIND'])\n\n# Label Encoding\n# Convert column to category\npro_data[\"WEATHER\"] = pro_data[\"WEATHER\"].astype('category')\npro_data[\"ROADCOND\"] = pro_data[\"ROADCOND\"].astype('category')\npro_data[\"LIGHTCOND\"] = pro_data[\"LIGHTCOND\"].astype('category')\n\n# Assign variable to new column for analysis\npro_data[\"WEATHER_CAT\"] = pro_data[\"WEATHER\"].cat.codes\npro_data[\"ROADCOND_CAT\"] = pro_data[\"ROADCOND\"].cat.codes\npro_data[\"LIGHTCOND_CAT\"] = pro_data[\"LIGHTCOND\"].cat.codes\n\npro_data.head(5)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Overview of the dataset"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "SEVERITYCODE        int64\nWEATHER          category\nROADCOND         category\nLIGHTCOND        category\nWEATHER_CAT          int8\nROADCOND_CAT         int8\nLIGHTCOND_CAT        int8\ndtype: object"
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "pro_data.dtypes"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "Clear                       111135\nRaining                      33145\nOvercast                     27714\nUnknown                      15091\nSnowing                        907\nOther                          832\nFog/Smog/Smoke                 569\nSleet/Hail/Freezing Rain       113\nBlowing Sand/Dirt               56\nSevere Crosswind                25\nPartly Cloudy                    5\nName: WEATHER, dtype: int64"
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "pro_data[\"WEATHER\"].value_counts()"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "Dry               124510\nWet                47474\nUnknown            15078\nIce                 1209\nSnow/Slush          1004\nOther                132\nStanding Water       115\nSand/Mud/Dirt         75\nOil                   64\nName: ROADCOND, dtype: int64"
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "pro_data[\"ROADCOND\"].value_counts()"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "Daylight                    116137\nDark - Street Lights On      48507\nUnknown                      13473\nDusk                          5902\nDawn                          2502\nDark - No Street Lights       1537\nDark - Street Lights Off      1199\nOther                          235\nDark - Unknown Lighting         11\nName: LIGHTCOND, dtype: int64"
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "pro_data[\"LIGHTCOND\"].value_counts()"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "1    136485\n2     58188\nName: SEVERITYCODE, dtype: int64"
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "pro_data[\"SEVERITYCODE\"].value_counts()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "As seen above, the Dataset is not balanced. To balance the dataset, the number of accidents with SEVERITYCODE=1 are downsampled"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "2    58188\n1    58188\nName: SEVERITYCODE, dtype: int64"
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from sklearn.utils import resample\n\npro_data_majority = pro_data[pro_data.SEVERITYCODE==1]\npro_data_minority = pro_data[pro_data.SEVERITYCODE==2]\n\n#Downsample majority class\npro_data_majority_downsampled = resample(pro_data_majority,\n                                        replace=False,\n                                        n_samples=58188,\n                                        random_state=123)\n\n# Combine minority class with downsampled majority class\npro_data_balanced = pd.concat([pro_data_majority_downsampled, pro_data_minority])\n\n# Display new class counts\npro_data_balanced.SEVERITYCODE.value_counts()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Methodology"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "A supervised learning model will be built using this data to come up with a formula that can predict the severity of an accident based on the inputs. Now that the data is ready, we can train the machine learning models with this data. The different models investigated here are:"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "1. K Nearest Neighbour:\n2. Decision Tree\n3. Logistic Regression"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Define the feature vector and the dependent variable values"
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([[ 6,  8,  2],\n       [ 1,  0,  5],\n       [10,  7,  8],\n       [ 1,  0,  5],\n       [ 1,  0,  5]], dtype=int8)"
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "import numpy as np\nX = np.asarray(pro_data_balanced[['WEATHER_CAT', 'ROADCOND_CAT', 'LIGHTCOND_CAT']])\nX[0:5]"
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([1, 1, 1, 1, 1])"
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "y = np.asarray(pro_data_balanced['SEVERITYCODE'])\ny [0:5]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Normalize the feature vector"
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int8 was converted to float64 by StandardScaler.\n  warnings.warn(msg, DataConversionWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int8 was converted to float64 by StandardScaler.\n  warnings.warn(msg, DataConversionWarning)\n"
                },
                {
                    "data": {
                        "text/plain": "array([[ 1.15236718,  1.52797946, -1.21648407],\n       [-0.67488   , -0.67084969,  0.42978835],\n       [ 2.61416492,  1.25312582,  2.07606076],\n       [-0.67488   , -0.67084969,  0.42978835],\n       [-0.67488   , -0.67084969,  0.42978835]])"
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from sklearn import preprocessing\nX = preprocessing.StandardScaler().fit(X).transform(X)\nX[0:5]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Make training and test splits of dataset"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "For this study, we will split the dataset as follows: 75% of the dataset becomes the training set and the rest 25% would be the test set."
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train set: (87282, 3) (87282,)\nTest set: (29094, 3) (29094,)\n"
                }
            ],
            "source": "from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 1. K Nearest Neighbours Model"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "In this method, the severity code of a test point is predicted by analyzing it's neighbors. It is important to find the best 'k', so that the model performs with the best accuracy."
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([0.51189249, 0.51206434, 0.51656699, 0.51457345, 0.5131986 ,\n       0.5119956 , 0.50938338, 0.50237162, 0.50154671, 0.50240599,\n       0.51464219, 0.50240599, 0.50941775, 0.50092803, 0.51168626,\n       0.510552  , 0.5068399 , 0.50989895, 0.50969272, 0.50900529,\n       0.51337045, 0.51347357, 0.51532962, 0.51206434])"
                    },
                    "execution_count": 40,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\n\nKs = 10\nmean_acc = np.zeros((Ks-1))\nstd_acc = np.zeros((Ks-1))\nConfustionMx = [];\nfor n in range(1,Ks):\n    \n    #Train Model and Predict  \n    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n    yhat=neigh.predict(X_test)\n    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n\n    \n    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n\nmean_acc"
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([1, 1, 1, 1, 1])"
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "k = 3 #best accuracy\n#Train Model and Predict  \nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\nneigh\n\nyhat_knn = neigh.predict(X_test)\nyhat_knn[0:5]"
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train set Accuracy:  0.5174148163424303\nTest set Accuracy:  0.5165669897573383\n"
                }
            ],
            "source": "print(\"Train set Accuracy: \", metrics.accuracy_score(y_train, neigh.predict(X_train)))\nprint(\"Test set Accuracy: \", metrics.accuracy_score(y_test, yhat_knn))"
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "[1 1 1 1 1]\n[2 2 1 1 1]\n"
                }
            ],
            "source": "print (yhat_knn [0:5])\nprint (y_test [0:5])"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 2. Decision Tree "
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([2, 2, 1, ..., 2, 1, 2])"
                    },
                    "execution_count": 45,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from sklearn import tree\n\nclf_tree = tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth = 10)\nclf_tree = clf_tree.fit(X_train, y_train)\nyhat_dt = clf_tree.predict(X_test)\nyhat_dt"
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "[2 2 1 1 2]\n[2 2 1 1 1]\n"
                }
            ],
            "source": "print (yhat_dt [0:5])\nprint (y_test [0:5])"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 3. Logistic Regression"
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "LogisticRegression(C=6, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='warn',\n          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n          tol=0.0001, verbose=0, warm_start=False)"
                    },
                    "execution_count": 27,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nLR = LogisticRegression(C=6, solver='liblinear').fit(X_train,y_train)\nLR"
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([1, 2, 1, ..., 2, 1, 2])"
                    },
                    "execution_count": 28,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "LRyhat = LR.predict(X_test)\nLRyhat"
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([[0.57263745, 0.42736255],\n       [0.47083235, 0.52916765],\n       [0.67438763, 0.32561237],\n       ...,\n       [0.47083235, 0.52916765],\n       [0.68326727, 0.31673273],\n       [0.46947758, 0.53052242]])"
                    },
                    "execution_count": 29,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "yhat_prob = LR.predict_proba(X_test)\nyhat_prob"
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "[1 2 1 1 1]\n[2 2 1 1 1]\n"
                }
            ],
            "source": "print (LRyhat [0:5])\nprint (y_test [0:5])"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Results and Evaluation"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "It is important to check how the different models perform using some evaluation metrics. This will help us identify the most reliable and robust model for this data science problem. For evaluating the models, we use the test set, which is 25% of the total dataset. There are different metrics that can be compared:\n1. Jaccard similarity score\n2. F1 score\n3. Log loss for logistic regression model"
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.metrics import jaccard_similarity_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### K Nearest Neighbour"
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.5165669897573383"
                    },
                    "execution_count": 33,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# Jaccard Similarity Score\njaccard_similarity_score(y_test, yhat_knn)"
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.46423304964062817"
                    },
                    "execution_count": 34,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# F1-SCORE\nf1_score(y_test, yhat_knn, average='macro')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "K=3 gives the maximum accuracy"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Decision Tree"
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.56688664329415"
                    },
                    "execution_count": 47,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# Jaccard Similarity Score\njaccard_similarity_score(y_test, yhat_dt)"
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.5431403441878632"
                    },
                    "execution_count": 48,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# F1-SCORE\nf1_score(y_test, yhat_dt, average='macro')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Logistic Regression"
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.5274283357393277"
                    },
                    "execution_count": 37,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# Jaccard Similarity Score\njaccard_similarity_score(y_test, LRyhat)"
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.5127901543870825"
                    },
                    "execution_count": 38,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# F1-SCORE\nf1_score(y_test, LRyhat, average='macro')"
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.6849604847680921"
                    },
                    "execution_count": 39,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# LOGLOSS\nyhat_prob = LR.predict_proba(X_test)\nlog_loss(y_test, yhat_prob)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Discussion"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "To start with, the data was loaded and studied. Columns with type 'object' were converted into categorial classes using label encoding. \n\nAn important observation at this stage was that the dataset was imablanced. The solution to this was downsampling the majority class with sklearn's resample tool. The majority class was downsampled appropriately in order to make the dataset balanced.\n\nAfter the preprocessing stage, the dataset was split into training and test sets in the ratio of 3:1. This is important in order to build accurate models and to prevent overfitting. The training data was then fed through three ML models: K-Nearest Neighbor, Decision Tree and Logistic Regression. \n\nEvaluation metrics used to test the accuracy of our models were jaccard index, f-1 score and additionally, log loss for logistic regression. Choosing different k values helped determine the most accurate KNN model. Similarly, the max depth of the Decision tree and C for Logistic regression is also varied and the most accurate values are found. The results of evaluation were compared to determine the best suited model for this data science problem."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Conclusion"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Based on the evaluation results, it can be observed that the decision tree performs the best. Hence, it could be chosen to model this dataset. "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}